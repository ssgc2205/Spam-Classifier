Does anyone know of any benchmark datasets used to evaluate classifier performance which are easily/naturally divided into two streams of data (or come from different modalities?). What I'm using at the moment are data which divide into audio+visual features, but it'd be useful to see if [this method I'm looking at] generalises to other types of data than frontal audiovisual data of humans. 

Thanks!